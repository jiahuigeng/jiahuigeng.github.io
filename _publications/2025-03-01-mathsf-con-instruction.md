---
title: "\mathsf {Con Instruction}: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities"
collection: publications
category: conferences
permalink: /publication/2025-03-01-mathsf-con-instruction
excerpt: 'This paper presents a novel approach for universal jailbreaking of multimodal large language models through non-textual modalities.'
date: 2025-03-01
venue: 'Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)'
paperurl: '#'
citation: 'J Geng, TT Tran, P Nakov, I Gurevych. (2025). &quot;\mathsf {Con Instruction}: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities.&quot; <i>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics</i>.'
---

This paper introduces a novel method for universal jailbreaking of multimodal large language models by exploiting non-textual modalities, revealing important security vulnerabilities in current multimodal AI systems.